---
title: "Week3"
author: "Sigurd Fyhn S칮rensen"
date: "2/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse)
```

# Week 3
Hello.... It is me.... Sigurd. :) I unfortunately cannot be with you this week. So I'll spare you for boring online class and instead created a super duper markdown file which will help you with the tons of exercises you get to do this week. 

I'll walk through a couple of code examples of how can create good function() with lots of different conditional statements. We will also look into the power of sampling and especially concatinating several nested sampling statements together. 


## Recap.
Last start out with a quick recap of some of the functions and idea from last lecture. 

In your own words describe the two different distributions and what they represent and how they differ from one another. 

# rbinom gives us a number of random values from a simple with a given probability. To do this it needs three informations: 
- Number of observations you want to see
- Number of trials per observation
- probability of success for each trial


# dbinom gives us probability densities: probabilities of getting a certain values on a number of trials. It needs this information:
- How many successes you want to investigate. It can be the probability of getting excactly 5 successes in n trials. Or an interval: getting 1:10 successes in n trials. 
- Then how many trials you do
- and the probability

```{r}
# we have 10 dices. We want to get a six. How many sixes, do when we throw 10 dices? This is repeated 2e4 times. 

x1 <- rbinom(2e4, size = 10, prob = 1/6)

```


```{r}
# If we roll a dice, what is the probability of getting a given value from 1 to 10 times in 10 trials?
# let's say, we want to get a 6 

x2 <- dbinom(0:10, size = 10 , prob = 1/6)
x2

plot(x = 0:10, y = x2, type = "l")

# the probability is highest that you get a 6 around 1 or 2 times. 

```
### Difference between two distributions. 
treatment A has a E(X) = 10 with sd = 1.5
treatment B has a E(X) = 5 with sd = 2
The two treatments are independent. 

estimate the difference in effect between the two distributions.
  1. Estimate the difference as a point estimate.
  2. Estimate the uncertainty surrounding the point estimate difference.

```{r}

 # The standard error is the standard deviation of an estimate

# difference is 10-5 = 5 with standard error: 

sqrt(1.5^2 + 2^2)

# a standard error of 2.5


```

*Bonus: (hard)*
How would the formula for the uncertainty estimate differ if we said that treatment A and B has a correlation coefficient of 0.6? 
  1. Describe in your own words how it would affect the difference between the two estimates. 
  2. Use the formula for differences between dependend variables to calculate a new estimate of uncertainity. 


# New stuff for today. 
## Some functions: 
### Sample
If I have an underlying idea about how many people eat the most candy on friday or saturday. We can use that to simulate the distribtuion. The sample function allows the outcome of sampling to be strings. 

```{r}
sample(c("friday","saturday"), size = 10, replace = TRUE, prob = c(0.55,0.45))


```
Replace = TRUE is required if you want a list with occurences. Try and change it to false and see what happens. 

first element C("friday", "saturday") is our possible outcomes. and prob = c(0.8, 0.7) is their corresponding probabilities. 


```{r}
#add sunday as another option and think add the proaability of sunday to the probability vector. 
sample(c("friday", "saturday", "sunday"), size = 10, replace = TRUE, prob = c(0.8, 0.7, 0.3))

```



### Seq()
A way to generate a vector of number bounded by the "from" and "to" statment. While "by" indicates the size of the steps. 
```{r}
#generate the numbers from 2 to 100 with steps of whole integers (1)
seq(from = 2, to = 100, by = 1)

```

```{r}
seq(from = 100, to = 150 , by = 0.4)

```

### rep()
Used if we wanna repeat something multiple times. 
```{r}
#repeat the number 1 one hundred times. 
rep(1, 100)
```


```{r}
rep(c(1,2), 100)

```
Now it repeats the vector c(1,2) 100 times. So the total outcome is 200 numbers in a vector. 



It doesn't have to be integers it can also repeat operations. Look at the code below and try and figure out the logic behind the outcome. 
```{r}
lul <- c(1,2,3)

rep(sum(lul)/lul, 100)

# sum = 6, s친 det er 6/1, 6/2, 6/3, hvert tal i vores vektor

```


### Loop()
If you wanan change something in each itteration of the repeat then loops() is a good intuitive starting points. R is super good at working with vectorized data and operations but loops is sometimes easier to understand but also computationaally more expensive. 

```{r}
x <- seq(from = 1 , to = 50, by = 0.5)

for (i in 1:length(x)){
  print(sum(x)/sum(x[1:i]))
}

# 1. tal = sum(x)/1, n칝ste er divideret med 2.5, n칝ste er divideret med 4.5, den n칝ste med 7, s친 forskellen mellem, hvad man dividerer med stiger med 0.5. f칮rst 1, s친 1.5, s친 2, s친 2.5 osv... 

```

# While loop
Here is an example of how to use while loops and the console as an input device.

Try and run the entire chunk and the specify in the console how many numbers of the fibonacci chain you want. 
```{r}
# take input from the user
nterms = as.integer(readline(prompt="How many terms?"))
# first two terms
n1 = 0
n2 = 1
count = 2
# check if the number of terms is valid
if(nterms <= 0) {
print("Plese enter a positive integer")
} else {
if(nterms == 1) {
print("Fibonacci sequence:")
print(n1)
} else {
print("Fibonacci sequence:")
print(n1)
print(n2)
while(count < nterms) {
nth = n1 + n2
print(nth)
# update values
n1 = n2
n2 = nth
count = count + 1
}
}
}
```
The number you type in the console in saved in "nterms". Walk through the line of codes and figure out how nterms is as conditionally statements. 

Question1: What happens if you get a negative number. (which line of code is responsible)

Question2: What happens if you type a positive number (which lines starts the sequence with the first two numbers) 

Question3: Which line of code stops the sequence when the desired n-terms is reached. 

Question4: Make the while loop print out nterms + 1 expression of the fibnonacci sequence. 



### Function 
Functions an easy way to reuse code and repeat a procedure many times. 

Key things to renember: 
 1. All variables made within a function is local variables which means you cannot use them outside of the function in the "global enviroment". 
 2. it is good code ethics to specify a return() statement which tells us what the final output should be of our function. If nothing is specified it will return the last statement calculated. 
 3. You can make functions with and without variables. f(x) is a function of x. f() is a function of nothing but it will still do the computations that you have specified. can be used to avoid a cluster of varaibles in the global enviroment.
 4. Be explicit in your functions variable names. 
 
 

Make a random function that returns the largest sum of two numbers.  
```{r}
test_function <- function(n1,n2,n3){
  if (n1 + n2 > n3){
    largest_sum <- paste("n1+ n2 =", n1 + n2)
  }
  if (n2 + n3 > n1){
    largest_sum <- paste("n2+ n3 =", n2 + n3)
  }
  if (n1 + n3 > n2){
    largest_sum <- paste("n1+ n3 =", n1 + n3) 
    
  }
  return(largest_sum)
}

test_function(6,0,-9)


```


__Your try__: Try and make a fun function with a least some conditional statements. 

```{r}

my_function <- function(n1,n2){
  if (n1/n2 < 1 ){
    same <- paste("n1 / n2 =", n1 / n2)
  }
  if (n2/n1 < 1){
    same <- paste("n2 / n1 =", n2 / n1)
    
  }
  return(same)
}

my_function(6,8)


```



## Sampling 1 of it's usage.  
A hypothethichal study has shown that left handed has a 60% chance of having an IQ above 160 
while Right-handed have a probability of 15%. About 10 % of the world are left handed. 

What is the overall probability of having an Iq over 160 across left and right handed
```{r}
#We can use the weighted average 
0.6*0.10 + 0.15*0.9

```
This is a point estimate but there is of course some uncertainity which could be calculated using the 
SD and SE for binomial data which we learned last time. 



But we can also simulate it. First we simulate 1 sample. 
```{r}
hand_func <- function(n){
  handedness <- sample(c("left_handed", "right_handed"), size = n, replace = TRUE, prob = c(0.1, 0.9))
  iq_160 <- rep(NA, n)
  for (i in 1:n){
    if (handedness[i] == "left_handed"){
      iq_160[i] <- rbinom(1, size= 1, prob = 0.6)
    }
    if (handedness[i] == "right_handed"){
      iq_160[i] <- rbinom(1,size = 1, prob = .15)
    }
  }
  return(iq_160)
}

iq_160 <- hand_func(2e4)

sum(iq_160 == 1)/length(iq_160)

```
If we repeated this prodcedure many times we could approximate the sampling distribution of our expected value which 
we can use to say something about the uncertainity of our point estimates.

```{r}
samp_dist_of_samp_means <- c()
for (i in 1:1000){
  samp_dist_of_samp_means[i] <- mean(hand_func(1e3))
}
hist(samp_dist_of_samp_means)
```
This tool is very useful not only for checking your own models but also a way to check other peoples reported results. You can use their parameter values to simulate data and repeat the process of simulation data to estimate the sampling dsitribution. 

# Exercises in the book. 
If you haven't finished the exercises from last time do so first. The exercises in chapter 5 builds on the knowledge gained from chapter 3 and 4. 

__Following Exercises in Chapter 5:__
5.1, 5.3, 5.4, 5.5 5.8, 5.9, 5.11, 5.12, 5.13

5.2 (semi-hard), 5.6 (hard)



## Exercise 5.1
5.1 Discrete probability simulation: Suppose that a basketball player has a 60% chance of making a shot, and he keeps taking shots until he misses two in a row. Also assume his shots are independent (so that each shot has 60% probability of success, no matter what happened before).
(a) Write an R function to simulate this process.
(b) Put the R function in a loop to simulate the process 1000 times. Use the simulation to estimate the mean and standard deviation of the total number of shots that the player will take, and plot a histogram representing the distribution of this random variable.
(c) Using your simulations, make a scatterplot of the number of shots the player will take and the proportion of shots that are successes.

```{r}


  # doesn't work   
hit_sim <- function(x){
  shots <- sample(c("hit","miss"), size = 1, replace = TRUE, prob = c(0.6, 0.4))
  misses <- rep(0, n)
for (i in 1:n) {
  if (shots[i] == "miss" & shots[i-1] == "miss") {
    misses[i] <- rbinom(1,size = 1, prob = .40)
  }
}
return(misses)
}



# Works!
n.sims <- 1000
hit_sim <- function(prob) {
  shots <- replicate(2, rbinom(1, 1, prob))
 while ((shots[length(shots)] + shots[length(shots) - 1]) != 0) { 
      shots <- c(shots, rbinom(1, 1, prob))
 }
return(shots)
}
hit_sim(0.6)



#Another one
n.sims <- 1000
n.balls <- rep(NA, 1000)
n.succ <- rep(NA, 1000)
for (s in 1:n.sims) {
    i=2
    shot <- NA
    shot[1] <- rbinom(1,1,.6)
    while(i>1) {
      shot[i] <- rbinom (1, 1, .6)
      if(shot[i]==0 & shot[i-1]==0) break
      i=1+i
    }
    
    n.balls[s] <- i; n.succ[s] <- sum(shot==1)
}

hist (n.balls, main="Simulated no of shots until 2 fails (p=.6)")
mean(n.balls)
sd(n.balls)
plot(n.balls, n.succ)

```

5.3 Binomial distribution: A player takes 10 basketball shots, with a 40% probability of making each shot. Assume the outcomes of the shots are independent.

(a) Write a line of R code to compute the probability that the player makes exactly 3 of the 10 shots.
(b) Write an R function to simulate the 10 shots. Loop this function 10 000 times and check that your simulated probability of making exactly 3 shots is close to the exact probability computed in (a)

```{r}

# a)
x3 <- dbinom(3, size = 10 , prob = .4)
x3

# b)
hit_sim <- function(n){
  shots <- sample(c("hit","miss"), size = n, replace = TRUE, prob = c(0.6, 0.4))
  misses <- rep(NA, n)
  for (i in 1:n){
    if (shots[i] == "hit"){
      misses[i] <- rbinom(1, size= 10, prob = 0.4)
    }
    if (shots[i] == "miss"){
      misses[i] <- rbinom(1,size = 10, prob = .6)
    }
  }
  return(misses)
}

 vec <- hit_sim(10000)
 vec
 sum(vec == 3)/length(vec)
 
 

  
```

# 5.4
Demonstration of the Central Limit Theorem: Let 洧논 = 洧논1 + 췅 췅 췅 + 洧논20, the sum of 20 independent uniform(0, 1) random variables. In R, create 1000 simulations of 洧논 and plot their histogram. What is the normal approximation to this distribution provided by the Central Limit Theorem? Overlay a graph of the normal density on top of the histogram. Comment on any differences between the histogram and the curve.



```{r}

x <- c()
for (i in 1:1000){
x[i] <- sum(runif(20, min= 0, max = 1))
x
}

df <- data.frame(x=x)
df1 <- data.frame(k = rnorm(1000))

ggplot(df, aes(x)) + 
geom_histogram(aes(y=..density..), 
binwidth = .2, 
colour = "black",fill ="white")+
geom_density(data= df1,color="red")+
geom_density(data=df,color="green")+
ggtitle("Simulation Histogram Plot")+
xlab("Data from df")+
ylab("Density")


?runif


```

